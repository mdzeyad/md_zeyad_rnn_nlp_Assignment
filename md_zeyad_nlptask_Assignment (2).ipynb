{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pil6EuSUaSEm"
      },
      "outputs": [],
      "source": [
        "# Simple RNN for Text Classification and Next Word Generation\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for Classification\n",
        "texts = [\n",
        "    \"Photosynthesis helps plants make food\",     # Science\n",
        "    \"Pythagoras theorem applies to triangles\",   # Math\n",
        "    \"The Renaissance was a historic period\",     # History\n",
        "    \"Nouns and verbs are parts of speech\"        # English\n",
        "]\n",
        "labels = [1, 0, 2, 3]  # 0=Math,1=Science,2=History,3=English"
      ],
      "metadata": {
        "id": "HcLXKhzNavii"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer and preprocessing\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=4)"
      ],
      "metadata": {
        "id": "WjT-y9fla3rq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Classification Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=8, input_length=max_len),\n",
        "    SimpleRNN(8),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sNb6mhlIa76u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(X, y, epochs=30, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yp59qyabAry",
        "outputId": "22c9ed3c-3e3c-498b-cefe-ad23f4a7e0f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7edb4c401010>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"Classification Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZq2UiebFzi",
        "outputId": "e97ae325-400d-4068-9dec-08b84f8b03ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next Word Generation Data (simple corpus)\n",
        "corpus = \"Photosynthesis is how plants make food. The Pythagorean theorem is useful in geometry.\""
      ],
      "metadata": {
        "id": "tgDOM3kbbKfa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare sequences\n",
        "tokenizer.fit_on_texts([corpus])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in corpus.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        input_sequences.append(token_list[:i+1])\n",
        "\n",
        "max_seq_len = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
        "\n",
        "X_gen = input_sequences[:, :-1]\n",
        "y_gen = input_sequences[:, -1]\n",
        "y_gen = tf.keras.utils.to_categorical(y_gen, num_classes=total_words)\n"
      ],
      "metadata": {
        "id": "_NH6-E-xbOwT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Generation Model\n",
        "gen_model = Sequential([\n",
        "    Embedding(total_words, 10, input_length=max_seq_len-1),\n",
        "    SimpleRNN(20),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "gen_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train Generation Model\n",
        "gen_model.fit(X_gen, y_gen, epochs=100, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoYkdi9ObV1y",
        "outputId": "0c09494f-2e1e-4f20-d815-39ac8dfc97b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7edb4c366550>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate words\n",
        "def generate_text(seed_text, next_words=10):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
        "        predicted = np.argmax(gen_model.predict(token_list, verbose=0), axis=1)[0]\n",
        "        output_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "d0fyl4fubfMl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample text\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generate_text(\"Photosynthesis is\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le0aYPhHbkwK",
        "outputId": "0ec564f2-772b-4ccb-dd73-643d1b9d7db8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "Photosynthesis is is is make food was plants plants in geometry pythagorean\n"
          ]
        }
      ]
    }
  ]
}